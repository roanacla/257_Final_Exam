# -*- coding: utf-8 -*-
"""Mayuri-alternus_vera_GO_ML_Factors_Integration_Sprint4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qiMwgUd7kTmHSxuSaD4mfG_n3q9RXK4N

# GO-ML Team
## Team members and factors

- Praveen Kumar Thakur - News Coverage
- Amit Vijapure - Stance Detection
- Mayuri Bhise - ClickBait
- Dhwani Sanghvi - Writing Style

## Connect to Google Drive to read datasets and pickled models
"""
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
# auth.authenticate_user()
# gauth = GoogleAuth()
# gauth.credentials = GoogleCredentials.get_application_default()
# drive = GoogleDrive(gauth)

"""## Import Libraries"""

import pandas as pd
import numpy as np
from wordcloud import WordCloud 
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk
# nltk.download('punkt')
# nltk.download('stopwords')
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_moons, make_circles, make_classification
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import SGDClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
import pickle


"""## Stance Detection"""

# temp_drive = drive.CreateFile({'id': 'https://drive.google.com/file/d/1woRoo1pna6hKoQ62JI3My2k4KCm7_6hh/view?usp=sharing'.split('/')[-2]})
# temp_drive.GetContentFile('SVM_stance_detection.model')

# temp_drive = drive.CreateFile({'id': 'https://drive.google.com/file/d/1tLxMwnfLhcmsVjWHnEa9TeeCrSdVHDM0/view?usp=sharing'.split('/')[-2]})
# temp_drive.GetContentFile('vector_stance_detection.pkl')

class StanceDetection():

    def __init__(self):        
        self.clf = pickle.load(open('/content/GoML/StanceDetection/SVM_stance_detection.model','rb'))
        self.vector: TfidfVectorizer = pickle.load(open('/content/GoML/StanceDetection/vector_stance_detection.pkl', 'rb'))
              
    def predict(self, text):
        a = self.vector.transform([text])
        predicted = self.clf.predict(a)
        predicedProb = self.clf.predict_proba(a)[0][0] + self.clf.predict_proba(a)[0][1]
        return predicedProb

def getStanceDetectionScore(text):
  text = re.sub('[^a-zA-Z ]', '', text).lower()
  text = ' '.join([w for w in text.split() if w not in stopwords.words('english')])
  return StanceDetection().predict(text)

getStanceDetectionScore("hey man how are you?")

"""## Clickbait Detection"""

# temp_drive = drive.CreateFile({'id': 'https://drive.google.com/file/d/16norntMWxj2ljjRY8UtFpyhtd2teEYJe/view?usp=sharing'.split('/')[-2]})
# temp_drive.GetContentFile('RF_clickbait.model')

# temp_drive = drive.CreateFile({'id': 'https://drive.google.com/file/d/1wEXHnjj0yAeTKJmj-noUIKFqhrMuHpwT/view?usp=sharing'.split('/')[-2]})
# temp_drive.GetContentFile('vector_clickbait.pkl')

class Clickbait():

    def __init__(self):        
        self.clf = pickle.load(open('/content/GoML/ClickBait/RF_clickbait.model','rb'))
        self.vector: TfidfVectorizer = pickle.load(open('/content/GoML/ClickBait/vector_clickbait.pkl', 'rb'))
              
    def predict(self, text):
        a = self.vector.transform([text])
        predicted = self.clf.predict(a)
        predicedProb = self.clf.predict_proba(a)[0][0] + self.clf.predict_proba(a)[0][1]
        return predicedProb

def getClickbaitScore(text):
  text = re.sub('[^a-zA-Z ]', '', text).lower()
  text = ' '.join([w for w in text.split() if w not in stopwords.words('english')])
  return Clickbait().predict(text)

getClickbaitScore("Should You bring the money now")

"""## News Coverage"""

# temp_drive = drive.CreateFile({'id': 'https://drive.google.com/file/d/1AKTM3HyxsC0uKfzVKsNdc_JQ5TXnjbht/view?usp=sharing'.split('/')[-2]})
# temp_drive.GetContentFile('RF_news_coverage.model')

# temp_drive = drive.CreateFile({'id': 'https://drive.google.com/file/d/1VAZF05pt59sYNjY4siLrkHY1208cf3rS/view?usp=sharing'.split('/')[-2]})
# temp_drive.GetContentFile('vector_news_coverage.pkl')

class NewsCoverage():

    def __init__(self):        
        self.clf = pickle.load(open('/content/GoML/NewsCoverage/RF_news_coverage.model','rb'))
        self.vector: TfidfVectorizer = pickle.load(open('/content/GoML/NewsCoverage/vector_news_coverage.pkl', 'rb'))
              
    def predict(self, text):
        a = self.vector.transform([text])
        #predicted = self.clf.predict(a)
        predicedProb = self.clf.predict_proba(a)[0][0] + self.clf.predict_proba(a)[0][1]
        return predicedProb

def getNewsCoverageScore(text):
  text = re.sub('[^a-zA-Z ]', '', text).lower()
  text = ' '.join([w for w in text.split() if w not in stopwords.words('english')])
  return NewsCoverage().predict(text)

getNewsCoverageScore("Donald trump will win")

"""## Writing Style"""

class WritingStyle():

  def __init__(self):
    # temp_writtingStyle_drive = drive.CreateFile({'id': 'https://drive.google.com/file/d/1iRZvUoFB6nRp0LNtyzDNYOFtNxF8Szxs/view?usp=sharing'.split('/')[-2]})
    # temp_writtingStyle_drive.GetContentFile('writting_style.pkl')
    self.clf = pickle.load(open('/content/GoML/WritingStyle/writting_style.pkl','rb'))

  def predict(self, text):
    predicted = self.clf.predict([text])
    predicedProb= self.clf.predict_proba([text])[:,1]
      
    return bool(predicted), float(predicedProb)

writingstyle = WritingStyle()

def WritingStyleScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake
  binaryValue, probValue  = writingstyle.predict(text)
  return (1 - float(probValue))

print(WritingStyleScore("College Republicans, YAF Sue Berkeley over Ann Coulter Event - Breitbart"))

"""## Identify Fake News"""

def isFakeNews(text, headline="", numAuthors = 0, source = "", party =""):
    accur = [0.87, 0.70, 0.82, 0.85] # using the (normalized) accuracy as weigths
    w = [float(i)/sum(accur) for i in accur]
    sumW = 0
    prob = []
    
    if text:
        prob.append(w[0] * getStanceDetectionScore(text))
        sumW += w[0]
    if text:
        prob.append(w[1] * getClickbaitScore(text))
        sumW += w[1]
    if text:
        prob.append(w[2] * getNewsCoverageScore(text))
        sumW += w[2]
    if text:
        prob.append(w[3] * WritingStyleScore(text))
        sumW += w[3]
    

    
    probTotal = sum(prob[0:len(prob)]) / sumW
    return probTotal
    
result = isFakeNews("Yesterday, the Brazilian soccer team won the world cup by defeating Argentina", "World Cup ends", 1, "cnn.com", "republican")
print(result)

if result < 0.05 :
  print("Pants-Fire!")
elif result < 0.20:
  print("False")
elif result < 0.40:
  print("Barely-True")
elif result < 0.60:
  print("Half-True")
elif result < 0.80:
  print("Mostly-True")
else:
    print("True")